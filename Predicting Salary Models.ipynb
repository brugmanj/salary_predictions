{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'John Brugman'\n",
    "__date__ = 'August 18 2020'\n",
    "__website__ = 'www.johnbrugman.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, train_feature_file, train_target_file, test_file, cat_cols, num_cols, target_col, id_col):\n",
    "        '''creates train and test dataframes'''\n",
    "        self.cat_cols = list(cat_cols)\n",
    "        self.num_cols = list(num_cols)\n",
    "        self.feature_cols = num_cols\n",
    "        self.target_col = target_col\n",
    "        self.id_col = id_col\n",
    "        self.label_encoders = {}\n",
    "        self.train_df = self._create_train(train_feature_file, train_target_file)\n",
    "        self.test_df = self._create_test(test_file)\n",
    "        \n",
    "    def label_encoder(self, df, cols):\n",
    "        '''encodes Labels'''\n",
    "        pass\n",
    "    \n",
    "    def inverse_encode_df(self, df, cols):\n",
    "        pass\n",
    "    \n",
    "    def _create_train(self, train_feature_file, train_target_file):\n",
    "        '''creates train dataframe from train feature and target files'''\n",
    "        train_feature_df = pd.read_csv(train_feature_file)\n",
    "        train_target_df = pd.read_csv(train_target_file)\n",
    "        train_df = pd.merge(train_feature_df, train_target_df)\n",
    "        return train_df\n",
    "    \n",
    "    def _create_test(self, test_file):\n",
    "        '''creates test dataframe from test_file'''\n",
    "        test_df = pd.read_csv(test_file)\n",
    "        return test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define ModelContainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelContainer:\n",
    "    def __init__(self, models = []):\n",
    "        '''initializes models and dictionaries'''\n",
    "        self.models = models\n",
    "        self.best_model = None\n",
    "        self.predictions = None\n",
    "        self.mean_mse = {}\n",
    "        \n",
    "    def add_model(self, model):\n",
    "        '''adds model to list of models'''\n",
    "        self.models.append(model)\n",
    "        \n",
    "    def cross_validate_model(self, data, k=3, num_procs=1):\n",
    "        '''calculates mse for models'''\n",
    "        feature_df = data.train_df[data.feature_cols]\n",
    "        target_df = data.train_df[data.target_col]\n",
    "        for model in self.models:\n",
    "            neg_mse = cross_val_score(model, X=feature_df, y=target_df, scoring='neg_mean_squared_error', cv = k, n_jobs=num_procs)\n",
    "            self.mean_mse[model] = np.mean(neg_mse) * -1.0\n",
    "        \n",
    "        \n",
    "    def select_best_model(self):\n",
    "        '''selects the best model based off mse'''\n",
    "        self.best_model = min(self.mean_mse, key=self.mean_mse.get)\n",
    "    \n",
    "    def best_model_fit(self, features, targets):\n",
    "        '''fits best model'''\n",
    "        self.best_model.fit(features, targets)\n",
    "            \n",
    "    def best_model_predict(self, features):\n",
    "        '''makes predictions with best model'''\n",
    "        self.predictions = self.best_model.predict(features)\n",
    "        \n",
    "    def save_results(self):\n",
    "        '''saves model and results'''\n",
    "        pass\n",
    "    \n",
    "    def print_summary(self):\n",
    "        print('The best model was', models.best_model)\n",
    "        print(f'This model had an mse of {models.mean_mse[models.best_model]}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Files\n",
    "train_feature_file = 'data/train_features.csv'\n",
    "train_target_file = 'data/train_salaries.csv'\n",
    "test_file = 'data/test_features.csv'\n",
    "\n",
    "# Feature Columns\n",
    "cat_cols = ['companyId', 'jobType', 'degree', 'major', 'industry']\n",
    "num_cols = ['yearsExperience', 'milesFromMetropolis']\n",
    "target_col = \"salary\"\n",
    "id_col = \"jobId\"\n",
    "\n",
    "# Parameters Needed\n",
    "num_procs = 4\n",
    "verbose_lvl = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Data Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(train_feature_file, train_target_file, test_file, cat_cols, num_cols, target_col, id_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating modelcontainer and adding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ModelContainer\n",
    "models = ModelContainer()\n",
    "\n",
    "# Adding Models to ModelContainer\n",
    "models.add_model(LinearRegression())\n",
    "models.add_model(RandomForestRegressor(n_estimators = 60, n_jobs=num_procs, max_depth=15, \\\n",
    "                                       min_samples_split=80, verbose=verbose_lvl))\n",
    "models.add_model(GradientBoostingRegressor(n_estimators=40, max_depth=7, loss='ls', verbose=verbose_lvl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validate Models, Selecting best_model and fitting/predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.cross_validate_model(data, k=2, num_procs=num_procs)\n",
    "models.select_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting and predicting with best_model\n",
    "models.best_model_fit(data.train_df[data.feature_cols], data.train_df[data.target_col])\n",
    "models.best_model_predict(data.test_df[data.feature_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was  GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=40,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
      "                          init=None, learning_rate=0.1, loss='ls', max_depth=7,\n",
      "                          max_features=None, max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=1, min_samples_split=2,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=40,\n",
      "                          n_iter_no_change=None, presort='deprecated',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False) had a mse of 1138.858117440976\n"
     ]
    }
   ],
   "source": [
    "models.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
